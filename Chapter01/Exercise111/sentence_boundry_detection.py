from nltk.tokenize import sent_tokenize

# The below code line will split the text into sentences.

sentences = sent_tokenize("We are reading a book. Do you know who is the "
                          "publisher? It is Packt. Packt is based out of Birmingham.")

# The below line of code will print the list of sentences.
print(sentences)
